{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.10",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 4310761,
          "sourceType": "datasetVersion",
          "datasetId": 2539169
        }
      ],
      "dockerImageVersionId": 30498,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "1 unet d",
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'brain-tumor-segmentation:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F2539169%2F4310761%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240418%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240418T173301Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D369ec3b9a16109ac8685dcb0c5aea777ab12727bbbf78bcf61695a3729eb44349487b05d1b0b49b64aae84ceabc2965a2c663802dd5aaf46e335b31061110fe3d819f3526c4877a7ba03cfc4ac08bbdf65d29b9963aa7c2db5dbf0cf2d1c3e895b2135848be956b602f1a3852a6b8965eecd911d8ae55bcfe960f658a682ec494aa74b17cf44ff676f1a4e9194344df7be0252d58d856b55284926ba7e8469ae07182bfcb2d9b504f0bcc01c8cb095e32c9985a04e86a2c830ba496e3b8278ebf50838e974350dbbe17e4fb2c8b630ded443f7b5418e3ad7fba875bd58c23d447684978703b30fe9703a96c5426aa525219d90dc36bb685db00ace60eba1124d'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "tL7VCRFtROql"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Imports**"
      ],
      "metadata": {
        "id": "gZmqvaHKROqn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from mpl_toolkits.axes_grid1 import ImageGrid\n",
        "from glob import glob\n",
        "import time\n",
        "import json\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.models import Model, load_model, save_model\n",
        "from tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, UpSampling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Conv2DTranspose, MaxPooling2D, concatenate, AveragePooling2D, Dense, Flatten\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras import models, layers, regularizers\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import glob\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Conv2DTranspose, concatenate, BatchNormalization, Activation"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-04-11T14:01:31.913799Z",
          "iopub.execute_input": "2024-04-11T14:01:31.914148Z",
          "iopub.status.idle": "2024-04-11T14:01:40.450195Z",
          "shell.execute_reply.started": "2024-04-11T14:01:31.914122Z",
          "shell.execute_reply": "2024-04-11T14:01:40.449377Z"
        },
        "trusted": true,
        "id": "kN-VgqlWROqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Variables**"
      ],
      "metadata": {
        "id": "KTWeXmjdROqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = (256, 256)\n",
        "\n",
        "train_files = glob.glob('../input/brain-tumor-segmentation/images/*.png')\n",
        "mask_files = glob.glob('../input/brain-tumor-segmentation/masks/*.png')\n",
        "\n",
        "EPOCHS = 80\n",
        "BATCH_SIZE = 32"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-11T14:01:40.452129Z",
          "iopub.execute_input": "2024-04-11T14:01:40.453187Z",
          "iopub.status.idle": "2024-04-11T14:01:40.779536Z",
          "shell.execute_reply.started": "2024-04-11T14:01:40.45315Z",
          "shell.execute_reply": "2024-04-11T14:01:40.778741Z"
        },
        "trusted": true,
        "id": "DU9rJizPROqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Visualization**"
      ],
      "metadata": {
        "id": "Bv2U1QOZROqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def diagnosis(mask):\n",
        "    value = np.max(cv2.imread(mask))\n",
        "    return '1' if value > 0 else '0'\n",
        "df = pd.DataFrame({\"image_path\": train_files,\n",
        "                    \"mask_path\": mask_files,\n",
        "                    \"diagnosis\": [diagnosis(x) for x in mask_files]})\n",
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-11T14:01:40.780741Z",
          "iopub.execute_input": "2024-04-11T14:01:40.781105Z",
          "iopub.status.idle": "2024-04-11T14:01:56.760534Z",
          "shell.execute_reply.started": "2024-04-11T14:01:40.781073Z",
          "shell.execute_reply": "2024-04-11T14:01:56.759598Z"
        },
        "trusted": true,
        "id": "hHnyZrbEROqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Splitting data into train and test**"
      ],
      "metadata": {
        "id": "9pZtVrZJROqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "df_train, df_test = train_test_split(df, test_size=0.15)\n",
        "df_train, df_val = train_test_split(df_train, test_size=0.15)\n",
        "print(df_train.values.shape)\n",
        "print(df_val.values.shape)\n",
        "print(df_test.values.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-11T14:01:59.242514Z",
          "iopub.execute_input": "2024-04-11T14:01:59.242813Z",
          "iopub.status.idle": "2024-04-11T14:01:59.251488Z",
          "shell.execute_reply.started": "2024-04-11T14:01:59.242787Z",
          "shell.execute_reply": "2024-04-11T14:01:59.250383Z"
        },
        "trusted": true,
        "id": "F4niM7ILROqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "labels = ['Training', 'Validation', 'Testing']\n",
        "sizes = [2213, 391, 460]\n",
        "colors = ['blue', 'green', 'orange']\n",
        "plt.bar(labels, sizes, color=colors)\n",
        "plt.title('Dataset 2')\n",
        "for i, v in enumerate(sizes):\n",
        "    plt.text(i, v + 30, str(v), ha='center')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-11T14:01:59.252645Z",
          "iopub.execute_input": "2024-04-11T14:01:59.252933Z",
          "iopub.status.idle": "2024-04-11T14:01:59.421176Z",
          "shell.execute_reply.started": "2024-04-11T14:01:59.252908Z",
          "shell.execute_reply": "2024-04-11T14:01:59.420259Z"
        },
        "trusted": true,
        "id": "d7z80s-rROqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Augmentation & Processing**"
      ],
      "metadata": {
        "id": "Koh1_latROqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_generator(data_frame, batch_size, aug_dict,\n",
        "        image_color_mode=\"grayscale\",\n",
        "        mask_color_mode=\"grayscale\",\n",
        "        image_save_prefix=\"image\",\n",
        "        mask_save_prefix=\"mask\",\n",
        "        save_to_dir=None,\n",
        "        target_size=(256,256),\n",
        "        seed=1):\n",
        "\n",
        "    image_datagen = ImageDataGenerator(**aug_dict)\n",
        "    mask_datagen = ImageDataGenerator(**aug_dict)\n",
        "\n",
        "    image_generator = image_datagen.flow_from_dataframe(\n",
        "        data_frame,\n",
        "        x_col = \"image_path\",\n",
        "        class_mode = None,\n",
        "        color_mode = image_color_mode,\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "        save_to_dir = save_to_dir,\n",
        "        save_prefix  = image_save_prefix,\n",
        "        seed = seed)\n",
        "\n",
        "    mask_generator = mask_datagen.flow_from_dataframe(\n",
        "        data_frame,\n",
        "        x_col = \"mask_path\",\n",
        "        class_mode = None,\n",
        "        color_mode = mask_color_mode,\n",
        "        target_size = target_size,\n",
        "        batch_size = batch_size,\n",
        "        save_to_dir = save_to_dir,\n",
        "        save_prefix  = mask_save_prefix,\n",
        "        seed = seed)\n",
        "\n",
        "    train_gen = zip(image_generator, mask_generator)\n",
        "\n",
        "    for (img, mask) in train_gen:\n",
        "        img, mask = adjust_data(img, mask)\n",
        "        yield (img,mask)\n",
        "\n",
        "def adjust_data(img,mask):\n",
        "    img = img / 255.\n",
        "    mask = mask / 255.\n",
        "    mask[mask > 0.5] = 1\n",
        "    mask[mask <= 0.5] = 0\n",
        "\n",
        "    return (img, mask)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-11T14:01:59.422348Z",
          "iopub.execute_input": "2024-04-11T14:01:59.423592Z",
          "iopub.status.idle": "2024-04-11T14:01:59.434418Z",
          "shell.execute_reply.started": "2024-04-11T14:01:59.423541Z",
          "shell.execute_reply": "2024-04-11T14:01:59.433708Z"
        },
        "trusted": true,
        "id": "xvr7uvenROqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator_args = dict(rotation_range=0.1,\n",
        "                            width_shift_range=0.05,\n",
        "                            height_shift_range=0.05,\n",
        "                            shear_range=0.05,\n",
        "                            zoom_range=0.05,\n",
        "                            horizontal_flip=True,\n",
        "                            vertical_flip=True,\n",
        "                            fill_mode='nearest')\n",
        "\n",
        "train_gen = train_generator(df_train, BATCH_SIZE, train_generator_args, target_size=IMAGE_SIZE)\n",
        "\n",
        "val_gen = train_generator(df_val, BATCH_SIZE, dict(), target_size=IMAGE_SIZE)\n",
        "\n",
        "test_gen = train_generator(df_test, BATCH_SIZE, dict(), target_size=IMAGE_SIZE)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-11T14:01:59.435703Z",
          "iopub.execute_input": "2024-04-11T14:01:59.436037Z",
          "iopub.status.idle": "2024-04-11T14:01:59.446818Z",
          "shell.execute_reply.started": "2024-04-11T14:01:59.436006Z",
          "shell.execute_reply": "2024-04-11T14:01:59.445955Z"
        },
        "trusted": true,
        "id": "clDSw2fPROqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dice and IoU Loss Functions**"
      ],
      "metadata": {
        "id": "bR2qL9smROqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "smooth=1.\n",
        "\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true = K.flatten(y_true)\n",
        "    y_pred = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true * y_pred)\n",
        "    union = K.sum(y_true) + K.sum(y_pred)\n",
        "    return (2.0 * intersection + smooth) / (union + smooth)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1 - dice_coef(y_true, y_pred)\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    return dice_coef_loss(y_true, y_pred) + bce(y_true, y_pred)\n",
        "\n",
        "def iou(y_true, y_pred):\n",
        "    intersection = K.sum(y_true * y_pred)\n",
        "    sum_ = K.sum(y_true + y_pred)\n",
        "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
        "    return jac\n",
        "\n",
        "def iou_loss(y_true, y_pred):\n",
        "    return 1 - iou(y_true, y_pred)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-11T14:01:59.4479Z",
          "iopub.execute_input": "2024-04-11T14:01:59.44823Z",
          "iopub.status.idle": "2024-04-11T14:01:59.456666Z",
          "shell.execute_reply.started": "2024-04-11T14:01:59.4482Z",
          "shell.execute_reply": "2024-04-11T14:01:59.455793Z"
        },
        "trusted": true,
        "id": "1xjl95zrROqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Building Model : UNet**"
      ],
      "metadata": {
        "id": "lXPW7MQWROqp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block1(inputs, filters):\n",
        "    x = Conv2D(filters, (3, 3), padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(filters, (3, 3), padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def encoder_block1(inputs, filters):\n",
        "    x = conv_block1(inputs, filters)\n",
        "    p = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "    return x, p\n",
        "\n",
        "def decoder_block1(inputs, filters, concat_layer):\n",
        "    x = Conv2DTranspose(filters, (2, 2), strides=(2, 2), padding='same')(inputs)\n",
        "    x = concatenate([x, concat_layer])\n",
        "    x = conv_block1(x, filters)\n",
        "    return x\n",
        "\n",
        "def unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    s1, p1 = encoder_block1(inputs, 32)  # Reduce filters in encoder blocks\n",
        "    s2, p2 = encoder_block1(p1, 64)\n",
        "    s3, p3 = encoder_block1(p2, 128)\n",
        "    s4, p4 = encoder_block1(p3, 256)\n",
        "\n",
        "    b1 = conv_block1(p4, 512)  # Reduce filters in bottleneck block\n",
        "\n",
        "    d1 = decoder_block1(b1, 256, s4)  # Reduce filters in decoder blocks\n",
        "    d2 = decoder_block1(d1, 128, s3)\n",
        "    d3 = decoder_block1(d2, 64, s2)\n",
        "    d4 = decoder_block1(d3, 32, s1)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation=\"sigmoid\")(d4)\n",
        "\n",
        "    unet_model = Model(inputs, outputs, name=\"UNet\")\n",
        "    return unet_model\n",
        "\n",
        "unet_model = unet((256, 256, 1))\n",
        "unet_model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-11T14:01:59.459292Z",
          "iopub.execute_input": "2024-04-11T14:01:59.460048Z",
          "iopub.status.idle": "2024-04-11T14:02:02.554607Z",
          "shell.execute_reply.started": "2024-04-11T14:01:59.460022Z",
          "shell.execute_reply": "2024-04-11T14:02:02.552127Z"
        },
        "trusted": true,
        "id": "7Wb1ZxbOROqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Train the Model**"
      ],
      "metadata": {
        "id": "vYazHgQUROqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Adam(learning_rate=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-7, amsgrad=False)\n",
        "unet_model.compile(optimizer=opt, loss=bce_dice_loss, metrics=[\"accuracy\", iou, dice_coef])\n",
        "\n",
        "callbacks = [ModelCheckpoint('unet.hdf5', verbose=0, save_best_only=True),\n",
        "             ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, min_lr=1e-11),\n",
        "             EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)]\n",
        "\n",
        "history_unet = unet_model.fit(train_gen,\n",
        "                              steps_per_epoch=len(df_train) / BATCH_SIZE,\n",
        "                              epochs=EPOCHS,\n",
        "                              callbacks=callbacks,\n",
        "                              validation_data=val_gen,\n",
        "                              validation_steps=len(df_val) / BATCH_SIZE)"
      ],
      "metadata": {
        "scrolled": true,
        "execution": {
          "iopub.status.busy": "2024-04-11T14:02:02.555861Z",
          "iopub.execute_input": "2024-04-11T14:02:02.556157Z",
          "iopub.status.idle": "2024-04-11T14:42:17.294235Z",
          "shell.execute_reply.started": "2024-04-11T14:02:02.556131Z",
          "shell.execute_reply": "2024-04-11T14:42:17.293246Z"
        },
        "trusted": true,
        "id": "z1fXxVqiROqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Evaluation**"
      ],
      "metadata": {
        "id": "zMx75JKpROqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('unet.hdf5', custom_objects={'bce_dice_loss': bce_dice_loss, 'accuracy': \"accuracy\", 'iou': iou, 'dice_coef': dice_coef})\n",
        "results = unet_model.evaluate(test_gen, steps=len(df_test) / BATCH_SIZE)\n",
        "print(\"Loss:\", results[0])\n",
        "print(\"Accuracy:\", results[1])\n",
        "print(\"IoU Score:\", results[2])\n",
        "print(\"Dice Score:\", results[3])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-11T14:42:17.295612Z",
          "iopub.execute_input": "2024-04-11T14:42:17.295942Z",
          "iopub.status.idle": "2024-04-11T14:42:26.22242Z",
          "shell.execute_reply.started": "2024-04-11T14:42:17.295912Z",
          "shell.execute_reply": "2024-04-11T14:42:26.221466Z"
        },
        "trusted": true,
        "id": "HsI5mDaOROqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict = history_unet.history\n",
        "pd.DataFrame.from_dict(history_dict).to_csv('history_unet.csv', index = False)\n",
        "history_unet_df = pd.read_csv('history_unet.csv')\n",
        "\n",
        "# Set the height of each subplot\n",
        "fig, axs = plt.subplots(nrows=4, ncols=1, figsize=(8, 20))\n",
        "\n",
        "# Adjust the space between subplots\n",
        "plt.subplots_adjust(hspace=0.5)\n",
        "\n",
        "# Plot the loss\n",
        "axs[0].plot(history_unet_df['loss'], 'b-', label='Training Loss')\n",
        "axs[0].plot(history_unet_df['val_loss'], 'r-', label='Validation Loss')\n",
        "axs[0].set_xlabel('Epochs')\n",
        "axs[0].set_ylabel('Loss')\n",
        "axs[0].legend(loc='best')\n",
        "\n",
        "# Plot the accuracy\n",
        "axs[1].plot(history_unet_df['accuracy'], 'b-', label='Training Accuracy')\n",
        "axs[1].plot(history_unet_df['val_accuracy'], 'r-', label='Validation Accuracy')\n",
        "axs[1].set_xlabel('Epochs')\n",
        "axs[1].set_ylabel('Accuracy')\n",
        "axs[1].legend(loc='best')\n",
        "\n",
        "# Plot the IOU\n",
        "axs[2].plot(history_unet_df['iou'], 'b-', label='Training IOU')\n",
        "axs[2].plot(history_unet_df['val_iou'], 'r-', label='Validation IOU')\n",
        "axs[2].set_xlabel('Epochs')\n",
        "axs[2].set_ylabel('IOU')\n",
        "axs[2].legend(loc='best')\n",
        "\n",
        "# Plot the dice coefficient\n",
        "axs[3].plot(history_unet_df['dice_coef'], 'b-', label='Training Dice Coefficient')\n",
        "axs[3].plot(history_unet_df['val_dice_coef'], 'r-', label='Validation Dice Coefficient')\n",
        "axs[3].set_xlabel('Epochs')\n",
        "axs[3].set_ylabel('Dice Coefficient')\n",
        "axs[3].legend(loc='best')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-11T14:42:26.223701Z",
          "iopub.execute_input": "2024-04-11T14:42:26.224022Z",
          "iopub.status.idle": "2024-04-11T14:42:27.11026Z",
          "shell.execute_reply.started": "2024-04-11T14:42:26.223994Z",
          "shell.execute_reply": "2024-04-11T14:42:27.109372Z"
        },
        "trusted": true,
        "id": "viWzrE21ROqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test the model with an image**"
      ],
      "metadata": {
        "id": "cUTBeGoUROqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    # Select a random image from the test set\n",
        "    index = np.random.randint(1, len(df_test.index))\n",
        "\n",
        "    # Load the image and preprocess it\n",
        "    img = cv2.imread(df_test['image_path'].iloc[index], cv2.IMREAD_GRAYSCALE)\n",
        "    img = cv2.resize(img, IMAGE_SIZE)\n",
        "    img = img / 255\n",
        "    img = img[:, :, np.newaxis]\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "\n",
        "    # Measure the inference time for UNet\n",
        "    start_time = time.time()\n",
        "    pred_unet = unet_model.predict(img)\n",
        "    end_time = time.time()\n",
        "    unet_inference_time = (end_time - start_time) * 1000\n",
        "\n",
        "    # Plot the original image and masks, as well as the predictions\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(np.squeeze(img), cmap='gray')\n",
        "    plt.title('Image')\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(np.squeeze(cv2.imread(df_test['mask_path'].iloc[index])), cmap='gray')\n",
        "    plt.title('Ground Truth')\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(np.squeeze(pred_unet) > .5, cmap='gray')\n",
        "    plt.title('UNet Prediction')\n",
        "    plt.show()\n",
        "\n",
        "    # Print the inference time for UNet\n",
        "    print(f'UNet Inference Time: {unet_inference_time:.4f} ms')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-11T14:42:27.111818Z",
          "iopub.execute_input": "2024-04-11T14:42:27.112157Z",
          "iopub.status.idle": "2024-04-11T14:42:33.903048Z",
          "shell.execute_reply.started": "2024-04-11T14:42:27.112123Z",
          "shell.execute_reply": "2024-04-11T14:42:33.902178Z"
        },
        "trusted": true,
        "id": "5xLxhAmiROqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Highlighted Tumor**"
      ],
      "metadata": {
        "id": "bYKyMcYjROqq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "model_path = '/kaggle/working/unet.hdf5'\n",
        "model = load_model(model_path, compile=False)\n",
        "\n",
        "def highlight_tumor(image_path, model):\n",
        "    # Read the image\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    image = cv2.resize(image, (256, 256))\n",
        "    image = image / 255.0  # Normalize the image\n",
        "\n",
        "    # Expand dimensions to match model input shape\n",
        "    image = np.expand_dims(image, axis=(0, -1))\n",
        "\n",
        "    # Perform segmentation\n",
        "    mask = model.predict(image)\n",
        "\n",
        "    # Threshold the mask\n",
        "    threshold = 0.5\n",
        "    mask_binary = (mask > threshold).astype(np.uint8)\n",
        "\n",
        "    # Convert the original image to RGB (for visualization purposes)\n",
        "    original_image_rgb = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Resize the mask to match the size of the original image\n",
        "    highlight_mask_resized = cv2.resize(mask_binary[0], (original_image_rgb.shape[1], original_image_rgb.shape[0]))\n",
        "\n",
        "    # Create a mask to highlight the tumor region in red\n",
        "    highlight_mask = cv2.cvtColor(highlight_mask_resized, cv2.COLOR_GRAY2RGB)\n",
        "    highlight_mask[:, :, 0] = np.where(highlight_mask[:, :, 0] > 0, 255, 0)  # Set red channel to 255 where tumor is present\n",
        "    highlight_mask[:, :, 1] = 0  # Set green channel to 0\n",
        "    highlight_mask[:, :, 2] = 0  # Set blue channel to 0\n",
        "\n",
        "    # Combine the original image with the highlight mask\n",
        "    highlighted_image = cv2.addWeighted(original_image_rgb, 0.7, highlight_mask, 0.3, 0)\n",
        "\n",
        "    # Display the highlighted image\n",
        "    plt.imshow(highlighted_image)\n",
        "    plt.title('Highlighted Tumor')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "image_path = '/kaggle/input/brain-tumor-segmentation/images/1.png'  # Update with the path to your image file\n",
        "highlight_tumor(image_path, model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-11T14:42:33.904578Z",
          "iopub.execute_input": "2024-04-11T14:42:33.905156Z",
          "iopub.status.idle": "2024-04-11T14:42:35.287041Z",
          "shell.execute_reply.started": "2024-04-11T14:42:33.905119Z",
          "shell.execute_reply": "2024-04-11T14:42:35.286128Z"
        },
        "trusted": true,
        "id": "dxDqwYR1ROqq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}